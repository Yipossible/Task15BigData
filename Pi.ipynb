{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14165616\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import random\n",
    "sc = pyspark.SparkContext(appName=\"Pi\")\n",
    "num_samples = 100000000\n",
    "def inside(p):     \n",
    "  x, y = random.random(), random.random()\n",
    "  return x*x + y*y < 1\n",
    "count = sc.parallelize(range(0, num_samples)).filter(inside).count()\n",
    "pi = 4 * count / num_samples\n",
    "print(pi)\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+------------------------------------------+------+\n",
      "|sentence                           |words                                     |tokens|\n",
      "+-----------------------------------+------------------------------------------+------+\n",
      "|Hi I heard about Spark             |[hi, i, heard, about, spark]              |5     |\n",
      "|I wish Java could use case classes |[i, wish, java, could, use, case, classes]|7     |\n",
      "|Logistic,regression,models,are,neat|[logistic,regression,models,are,neat]     |1     |\n",
      "+-----------------------------------+------------------------------------------+------+\n",
      "\n",
      "+-----------------------------------+------------------------------------------+------+\n",
      "|sentence                           |words                                     |tokens|\n",
      "+-----------------------------------+------------------------------------------+------+\n",
      "|Hi I heard about Spark             |[hi, i, heard, about, spark]              |5     |\n",
      "|I wish Java could use case classes |[i, wish, java, could, use, case, classes]|7     |\n",
      "|Logistic,regression,models,are,neat|[logistic, regression, models, are, neat] |5     |\n",
      "+-----------------------------------+------------------------------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"test\").getOrCreate()\n",
    "\n",
    "sentenceDataFrame = spark.createDataFrame([\n",
    "    (0, \"Hi I heard about Spark\"),\n",
    "    (1, \"I wish Java could use case classes\"),\n",
    "    (2, \"Logistic,regression,models,are,neat\")\n",
    "], [\"id\", \"sentence\"])\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"sentence\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "# alternatively, pattern=\"\\\\w+\", gaps(False)\n",
    "\n",
    "countTokens = udf(lambda words: len(words), IntegerType())\n",
    "\n",
    "\n",
    "tokenized = tokenizer.transform(sentenceDataFrame)\n",
    "tokenized.select(\"sentence\", \"words\")\\\n",
    "    .withColumn(\"tokens\", countTokens(col(\"words\"))).show(truncate=False)\n",
    "\n",
    "regexTokenized = regexTokenizer.transform(sentenceDataFrame)\n",
    "regexTokenized.select(\"sentence\", \"words\") \\\n",
    "    .withColumn(\"tokens\", countTokens(col(\"words\"))).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, spark i j k) --> prob=[0.334518607597,0.665481392403], prediction=1.000000\n",
      "(5, l m n) --> prob=[0.668102477307,0.331897522693], prediction=0.000000\n",
      "(6, spark hadoop spark) --> prob=[0.111525601523,0.888474398477], prediction=1.000000\n",
      "(7, apache hadoop) --> prob=[0.668102477307,0.331897522693], prediction=0.000000\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "\n",
    "# Prepare training documents from a list of (id, text, label) tuples.\n",
    "training = spark.createDataFrame([\n",
    "    (0, \"a b c d e spark\", 1.0),\n",
    "    (1, \"b d\", 0.0),\n",
    "    (2, \"spark f g h\", 1.0),\n",
    "    (3, \"hadoop mapreduce\", 0.0)\n",
    "], [\"id\", \"text\", \"label\"])\n",
    "\n",
    "# Configure an ML pipeline, which consists of one stages: tokenizer, hashingTF, and lr.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "model = pipeline.fit(training)\n",
    "\n",
    "# Prepare test documents, which are unlabeled (id, text) tuples.11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
    "test = spark.createDataFrame([\n",
    "    (4, \"spark i j k\"),\n",
    "    (5, \"l m n\"),\n",
    "    (6, \"spark hadoop spark\"),\n",
    "    (7, \"apache hadoop\")\n",
    "], [\"id\", \"text\"])\n",
    "\n",
    "# Make predictions on test documents and print columns of interest.\n",
    "prediction = model.transform(test)\n",
    "selected = prediction.select(\"id\", \"text\", \"probability\", \"prediction\")\n",
    "for row in selected.collect():\n",
    "    rid, text, prob, prediction = row\n",
    "    print(\"(%d, %s) --> prob=%s, prediction=%f\" % (rid, text, str(prob), prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|   _c0|                 _c1|                 _c2|\n",
      "+------+--------------------+--------------------+\n",
      "|100001|            Bullet01|Versatile connect...|\n",
      "|100001|            Bullet02|Stronger than ang...|\n",
      "|100001|            Bullet03|Help ensure joint...|\n",
      "|100001|            Bullet04|Dimensions: 3 in....|\n",
      "|100001|            Bullet05|Made from 12-Gaug...|\n",
      "|100001|            Bullet06|Galvanized for ex...|\n",
      "|100001|            Bullet07|Install with 10d ...|\n",
      "|100001|               Gauge|                  12|\n",
      "|100001|            Material|    Galvanized Steel|\n",
      "|100001|      MFG Brand Name|  Simpson Strong-Tie|\n",
      "|100001|    Number of Pieces|                   1|\n",
      "|100001| Product Depth (in.)|                 1.5|\n",
      "|100001|Product Height (in.)|                   3|\n",
      "|100001|Product Weight (lb.)|                0.26|\n",
      "|100001| Product Width (in.)|                   3|\n",
      "|100002|  Application Method|  Brush,Roller,Spray|\n",
      "|100002|Assembled Depth (...|             6.63 in|\n",
      "|100002|Assembled Height ...|             7.76 in|\n",
      "|100002|Assembled Width (...|             6.63 in|\n",
      "|100002|            Bullet01|Revives wood and ...|\n",
      "+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "df = spark.read.load(\"/Users/yiwang/Documents/YiWang/Ebiz/Task 15/attributes.csv\", format=\"csv\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+-----+\n",
      "|   pid|               title|                term|score|\n",
      "+------+--------------------+--------------------+-----+\n",
      "|100001|Simpson Strong-Ti...|       angle bracket|  3.0|\n",
      "|100001|Simpson Strong-Ti...|           l bracket|  2.5|\n",
      "|100002|BEHR Premium Text...|           deck over|  3.0|\n",
      "|100005|Delta Vero 1-Hand...|    rain shower head| 2.33|\n",
      "|100005|Delta Vero 1-Hand...|  shower only faucet| 2.67|\n",
      "|100006|Whirlpool 1.9 cu....|      convection otr|  3.0|\n",
      "|100006|Whirlpool 1.9 cu....|microwave over stove| 2.67|\n",
      "|100006|Whirlpool 1.9 cu....|          microwaves|  3.0|\n",
      "|100007|Lithonia Lighting...|     emergency light| 2.67|\n",
      "|100009|House of Fara 3/4...|             mdf 3/4|  3.0|\n",
      "+------+--------------------+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+------+--------------------+\n",
      "|   pid|         description|\n",
      "+------+--------------------+\n",
      "|100002|BEHR Premium Text...|\n",
      "|100003|Classic architect...|\n",
      "|100004|The Grape Solar 2...|\n",
      "|100005|Update your bathr...|\n",
      "|100006|Achieving delicio...|\n",
      "|100007|The Quantum Adjus...|\n",
      "|100008|The Teks #10 x 1-...|\n",
      "|100009|Get the House of ...|\n",
      "|100010|Valley View Indus...|\n",
      "|100011|\"Recycler 22 in. ...|\n",
      "+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+------+--------------------+--------------------+-----+--------------------+------------+--------------+-----------------+\n",
      "|   pid|               title|                term|score|         description|       brand|      material|            color|\n",
      "+------+--------------------+--------------------+-----+--------------------+------------+--------------+-----------------+\n",
      "|100170|Dyna-Glo Pro 125,...|     kerosene heater|  1.0|Dyna-Glo Pro port...|Dyna-Glo Pro|         Steel|Oranges / Peaches|\n",
      "|100170|Dyna-Glo Pro 125,...|      lp gas heaters| 2.67|Dyna-Glo Pro port...|Dyna-Glo Pro|         Steel|Oranges / Peaches|\n",
      "|100170|Dyna-Glo Pro 125,...|   portable air tank| 1.67|Dyna-Glo Pro port...|Dyna-Glo Pro|         Steel|Oranges / Peaches|\n",
      "|100170|Dyna-Glo Pro 125,...| thin propane heater| 2.33|Dyna-Glo Pro port...|Dyna-Glo Pro|         Steel|Oranges / Peaches|\n",
      "|100274|Milwaukee M12 12-...|        milwakee M12|  3.0|Milwaukee REDLITH...|   Milwaukee|          null|              Red|\n",
      "|100274|Milwaukee M12 12-...|       milwaukee m12| 1.67|Milwaukee REDLITH...|   Milwaukee|          null|              Red|\n",
      "|100274|Milwaukee M12 12-...|photoelectric/ion...| 1.67|Milwaukee REDLITH...|   Milwaukee|          null|              Red|\n",
      "|100446|Glacier Bay 2-pie...|  glaciar bay toiled| 2.67|Choose a half flu...| Glacier Bay|Vitreous China|            Beige|\n",
      "|100446|Glacier Bay 2-pie...|glacier bay high ...| 1.67|Choose a half flu...| Glacier Bay|Vitreous China|            Beige|\n",
      "|100446|Glacier Bay 2-pie...|  toilet glacier bay|  3.0|Choose a half flu...| Glacier Bay|Vitreous China|            Beige|\n",
      "+------+--------------------+--------------------+-----+--------------------+------------+--------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType,StringType,IntegerType\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sql_sc = SQLContext(sc)\n",
    "\n",
    "trainSchema = StructType([\n",
    "    StructField(\"id\", IntegerType()),\n",
    "    StructField(\"pid\", IntegerType()),\n",
    "    StructField(\"title\", StringType()),\n",
    "    StructField(\"term\", StringType()),\n",
    "    StructField(\"score\", DoubleType())\n",
    "])\n",
    "\n",
    "titleSchema = StructType([\n",
    "    StructField(\"pid\", IntegerType()),\n",
    "    StructField(\"title\", StringType())\n",
    "])\n",
    "\n",
    "descriptionSchema = StructType([\n",
    "    StructField(\"pid\", IntegerType()),\n",
    "    StructField(\"description\", StringType())\n",
    "])\n",
    "\n",
    "attrSchema = StructType([\n",
    "    StructField(\"pid\", IntegerType()),\n",
    "    StructField(\"name\", StringType()),\n",
    "    StructField(\"value\", StringType()),\n",
    "])\n",
    "\n",
    "title = sql_sc.read.format(\"com.databricks.spark.csv\").option(\"header\",\"true\").schema(trainSchema).load(\"/Users/yiwang/Documents/YiWang/Ebiz/Task 15/train.csv\")\n",
    "train = sql_sc.read.format(\"com.databricks.spark.csv\").option(\"header\",\"true\").schema(titleSchema).load(\"/Users/yiwang/Documents/YiWang/Ebiz/Task 15/RawTrain.csv\")\n",
    "test=sql_sc.read.format(\"com.databricks.spark.csv\").option(\"header\",\"true\")    .schema(dataSchema).load(\"/Users/yiwang/Documents/YiWang/Ebiz/Task 15/test.csv\")\n",
    "attr = sql_sc.read.format(\"com.databricks.spark.csv\").option(\"header\",\"true\").schema(attrSchema).load(\"/Users/yiwang/Documents/YiWang/Ebiz/Task 15/attributes.csv\")\n",
    "\n",
    "description = sql_sc.read.format(\"com.databricks.spark.csv\").option(\"header\",\"true\").schema(descriptionSchema).load(\"/Users/yiwang/Documents/YiWang/Ebiz/Task 15/product_descriptions.csv\")\n",
    "title= title.drop(title.id)\n",
    "title.show(10)\n",
    "description.show(10)\n",
    "\n",
    "\n",
    "attr.createOrReplaceTempView(\"attr\")\n",
    "#get brand, color and material\n",
    "brand = sql_sc.sql(\"SELECT pid,value as brand from attr where name = 'MFG Brand Name'\")\n",
    "material = sql_sc.sql(\"SELECT pid,value as material from attr where name = 'Material'\")\n",
    "color = sql_sc.sql(\"SELECT pid,value as color from attr where name = 'Color Family'\")\n",
    "\n",
    "#result=train.union(test)\n",
    "title=title.join(description, title.pid == description.pid, \"left\").drop(description.pid)\n",
    "title=title.join(brand, title.pid == brand.pid, \"left\").drop(brand.pid)\n",
    "title=title.join(material, title.pid== material.pid,\"left\").drop(material.pid)\n",
    "title=title.join(color, title.pid == color.pid,\"left\").drop(color.pid)\n",
    "\n",
    "title.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+-----+--------------------+------------+--------------+-----------------+\n",
      "|   pid|               title|                term|score|         description|       brand|      material|            color|\n",
      "+------+--------------------+--------------------+-----+--------------------+------------+--------------+-----------------+\n",
      "|100170|Dyna-Glo Pro 125,...|     kerosene heater|  1.0|Dyna-Glo Pro port...|Dyna-Glo Pro|         Steel|Oranges / Peaches|\n",
      "|100170|Dyna-Glo Pro 125,...|      lp gas heaters| 2.67|Dyna-Glo Pro port...|Dyna-Glo Pro|         Steel|Oranges / Peaches|\n",
      "|100170|Dyna-Glo Pro 125,...|   portable air tank| 1.67|Dyna-Glo Pro port...|Dyna-Glo Pro|         Steel|Oranges / Peaches|\n",
      "|100170|Dyna-Glo Pro 125,...| thin propane heater| 2.33|Dyna-Glo Pro port...|Dyna-Glo Pro|         Steel|Oranges / Peaches|\n",
      "|100274|Milwaukee M12 12-...|        milwakee M12|  3.0|Milwaukee REDLITH...|   Milwaukee|         empty|              Red|\n",
      "|100274|Milwaukee M12 12-...|       milwaukee m12| 1.67|Milwaukee REDLITH...|   Milwaukee|         empty|              Red|\n",
      "|100274|Milwaukee M12 12-...|photoelectric/ion...| 1.67|Milwaukee REDLITH...|   Milwaukee|         empty|              Red|\n",
      "|100446|Glacier Bay 2-pie...|  glaciar bay toiled| 2.67|Choose a half flu...| Glacier Bay|Vitreous China|            Beige|\n",
      "|100446|Glacier Bay 2-pie...|glacier bay high ...| 1.67|Choose a half flu...| Glacier Bay|Vitreous China|            Beige|\n",
      "|100446|Glacier Bay 2-pie...|  toilet glacier bay|  3.0|Choose a half flu...| Glacier Bay|Vitreous China|            Beige|\n",
      "+------+--------------------+--------------------+-----+--------------------+------------+--------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "title=title.withColumn(\n",
    "    \"color\", when(col(\"color\").isNull(), \"empty\").otherwise(col(\"color\")))\n",
    "title=title.withColumn(\n",
    "    \"brand\", when(col(\"brand\").isNull(), \"empty\").otherwise(col(\"brand\")))\n",
    "title=title.withColumn(\n",
    "    \"material\", when(col(\"material\").isNull(), \"empty\").otherwise(col(\"material\")))\n",
    "title=title.withColumn(\n",
    "    \"description\", when(col(\"description\").isNull(), \"empty\").otherwise(col(\"description\")))\n",
    "\n",
    "\n",
    "title.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----+--------------------+\n",
      "|   pid|                term|score|       joined_column|\n",
      "+------+--------------------+-----+--------------------+\n",
      "|100170|     kerosene heater|  1.0|Dyna-Glo Pro port...|\n",
      "|100170|      lp gas heaters| 2.67|Dyna-Glo Pro port...|\n",
      "|100170|   portable air tank| 1.67|Dyna-Glo Pro port...|\n",
      "|100170| thin propane heater| 2.33|Dyna-Glo Pro port...|\n",
      "|100274|        milwakee M12|  3.0|Milwaukee REDLITH...|\n",
      "|100274|       milwaukee m12| 1.67|Milwaukee REDLITH...|\n",
      "|100274|photoelectric/ion...| 1.67|Milwaukee REDLITH...|\n",
      "|100446|  glaciar bay toiled| 2.67|Choose a half flu...|\n",
      "|100446|glacier bay high ...| 1.67|Choose a half flu...|\n",
      "|100446|  toilet glacier bay|  3.0|Choose a half flu...|\n",
      "+------+--------------------+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as sf\n",
    "title = title.withColumn('joined_column', \n",
    "                    sf.concat( sf.col('description'),sf.lit('_'), sf.col('title'),sf.lit('_'), sf.col('brand'), sf.lit('_'), sf.col('material'),sf.lit('_'), sf.col('color')))\n",
    "title = title.drop(title.title).drop(title.description).drop(title.brand).drop(title.material).drop(title.color)\n",
    "title.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|   pid|                term|score|       joined_column|          term_words|            term_idf|        joined_words|          joined_idf|\n",
      "+------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|100170|     kerosene heater|  1.0|Dyna-Glo Pro port...|  [kerosene, heater]|(10,[0,8],[1.1296...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|\n",
      "|100170|      lp gas heaters| 2.67|Dyna-Glo Pro port...|  [lp, gas, heaters]|(10,[2,5,9],[1.26...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|\n",
      "|100170|   portable air tank| 1.67|Dyna-Glo Pro port...|[portable, air, t...|(10,[3,4,7],[1.25...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|\n",
      "|100170| thin propane heater| 2.33|Dyna-Glo Pro port...|[thin, propane, h...|(10,[0,2,7],[1.12...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|\n",
      "|100274|        milwakee M12|  3.0|Milwaukee REDLITH...|     [milwakee, m12]|(10,[4,6],[1.2325...|[milwaukee, redli...|(10,[0,1,2,3,4,5,...|\n",
      "|100274|       milwaukee m12| 1.67|Milwaukee REDLITH...|    [milwaukee, m12]|(10,[0,6],[1.1296...|[milwaukee, redli...|(10,[0,1,2,3,4,5,...|\n",
      "|100274|photoelectric/ion...| 1.67|Milwaukee REDLITH...|[photoelectric/io...|(10,[0,2,4],[1.12...|[milwaukee, redli...|(10,[0,1,2,3,4,5,...|\n",
      "|100446|  glaciar bay toiled| 2.67|Choose a half flu...|[glaciar, bay, to...|(10,[1,9],[2.7061...|[choose, a, half,...|(10,[0,1,2,3,4,5,...|\n",
      "|100446|glacier bay high ...| 1.67|Choose a half flu...|[glacier, bay, hi...|(10,[1,6,7,9],[1....|[choose, a, half,...|(10,[0,1,2,3,4,5,...|\n",
      "|100446|  toilet glacier bay|  3.0|Choose a half flu...|[toilet, glacier,...|(10,[1,9],[1.3530...|[choose, a, half,...|(10,[0,1,2,3,4,5,...|\n",
      "|100446|  toilets in biscuit|  3.0|Choose a half flu...|[toilets, in, bis...|(10,[5,6,9],[1.40...|[choose, a, half,...|(10,[0,1,2,3,4,5,...|\n",
      "|100800|coating sealer fo...|  2.0|Seal-Krete Epoxy ...|[coating, sealer,...|(10,[2,3,5,6],[1....|[seal-krete, epox...|(10,[0,1,2,3,4,5,...|\n",
      "|100986|            slatwall|  1.0|Keep your garage ...|          [slatwall]|(10,[1],[1.353078...|[keep, your, gara...|(10,[0,1,2,3,4,5,...|\n",
      "|101055|12 x 12 concrete ...|  2.0|The Pavestone 0.5...|[12, x, 12, concr...|(10,[0,6],[4.5184...|[the, pavestone, ...|(10,[0,1,2,3,4,5,...|\n",
      "|101055|      12 x 12 pavers| 2.67|The Pavestone 0.5...| [12, x, 12, pavers]|(10,[0,6],[3.3888...|[the, pavestone, ...|(10,[0,1,2,3,4,5,...|\n",
      "|101055|        12x12 pavers| 1.67|The Pavestone 0.5...|     [12x12, pavers]|(10,[6,9],[1.3081...|[the, pavestone, ...|(10,[0,1,2,3,4,5,...|\n",
      "|101055|   paver base gravel| 2.67|The Pavestone 0.5...|[paver, base, gra...|(10,[3,4,9],[1.25...|[the, pavestone, ...|(10,[0,1,2,3,4,5,...|\n",
      "|101055|        paver stones| 2.33|The Pavestone 0.5...|     [paver, stones]|(10,[9],[2.362761...|[the, pavestone, ...|(10,[0,1,2,3,4,5,...|\n",
      "|101055|        paving brick| 1.67|The Pavestone 0.5...|     [paving, brick]|(10,[5,7],[1.4026...|[the, pavestone, ...|(10,[0,1,2,3,4,5,...|\n",
      "|101094|1 lite french doo...| 2.33|Clear Pine is a s...|[1, lite, french,...|(10,[2,3,4,8],[1....|[clear, pine, is,...|(10,[0,1,2,3,4,5,...|\n",
      "+------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "#tokenize terms\n",
    "tokenizer = Tokenizer(inputCol=\"term\", outputCol=\"term_words\")\n",
    "temp = tokenizer.transform(title)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"term_words\", outputCol=\"rawFeatures\", numFeatures=10)\n",
    "temp = hashingTF.transform(temp)\n",
    "\n",
    "idf = IDF(inputCol = \"rawFeatures\", outputCol=\"term_idf\")\n",
    "idfModel = idf.fit(temp)\n",
    "temp = idfModel.transform(temp)\n",
    "temp=temp.drop(\"rawFeatures\")\n",
    "\n",
    "#tokenize joined_column\n",
    "tokenizer = Tokenizer(inputCol=\"joined_column\", outputCol=\"joined_words\")\n",
    "temp = tokenizer.transform(temp)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"joined_words\", outputCol=\"rawFeatures\", numFeatures=10)\n",
    "temp = hashingTF.transform(temp)\n",
    "\n",
    "idf = IDF(inputCol = \"rawFeatures\", outputCol=\"joined_idf\")\n",
    "idfModel = idf.fit(temp)\n",
    "temp = idfModel.transform(temp)\n",
    "temp=temp.drop(\"rawFeatures\")\n",
    "\n",
    "temp.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|   pid|               term|score|       joined_column|          term_words|            term_idf|        joined_words|          joined_idf|\n",
      "+------+-------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|100170|    kerosene heater|  1.0|Dyna-Glo Pro port...|  [kerosene, heater]|(10,[0,8],[1.1296...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|\n",
      "|100170|     lp gas heaters| 2.67|Dyna-Glo Pro port...|  [lp, gas, heaters]|(10,[2,5,9],[1.26...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|\n",
      "|100170|  portable air tank| 1.67|Dyna-Glo Pro port...|[portable, air, t...|(10,[3,4,7],[1.25...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|\n",
      "|100170|thin propane heater| 2.33|Dyna-Glo Pro port...|[thin, propane, h...|(10,[0,2,7],[1.12...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|\n",
      "|100274|       milwakee M12|  3.0|Milwaukee REDLITH...|     [milwakee, m12]|(10,[4,6],[1.2325...|[milwaukee, redli...|(10,[0,1,2,3,4,5,...|\n",
      "+------+-------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = temp\n",
    "result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|   pid|               term|score|       joined_column|          term_words|            term_idf|        joined_words|          joined_idf|match|\n",
      "+------+-------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|100170|    kerosene heater|  1.0|Dyna-Glo Pro port...|  [kerosene, heater]|(10,[0,8],[1.1296...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|    0|\n",
      "|100170|     lp gas heaters| 2.67|Dyna-Glo Pro port...|  [lp, gas, heaters]|(10,[2,5,9],[1.26...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|    0|\n",
      "|100170|  portable air tank| 1.67|Dyna-Glo Pro port...|[portable, air, t...|(10,[3,4,7],[1.25...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|    0|\n",
      "|100170|thin propane heater| 2.33|Dyna-Glo Pro port...|[thin, propane, h...|(10,[0,2,7],[1.12...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|    0|\n",
      "|100274|       milwakee M12|  3.0|Milwaukee REDLITH...|     [milwakee, m12]|(10,[4,6],[1.2325...|[milwaukee, redli...|(10,[0,1,2,3,4,5,...|    0|\n",
      "+------+-------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "#match words and then proceed to jaccard_similarity_score\n",
    "def countMatchedWords(joined, term):\n",
    "    l1=len(joined)\n",
    "    l2=len(term)\n",
    "    match = 0\n",
    "    for i in range(l1):\n",
    "        for j in range(l2):\n",
    "            if joined[i] == term[j]:\n",
    "                match+=2\n",
    "            elif joined[i] in term[j]:\n",
    "                match+=1\n",
    "            elif term[j] in joined[i]:\n",
    "                match+=1\n",
    "        return match\n",
    "matchUDF=udf(countMatchedWords, IntegerType())\n",
    "\n",
    "result=result.withColumn(\"match\", matchUDF(\"joined_words\", \"term_words\"))\n",
    "result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|   pid|               term|score|       joined_column|          term_words|            term_idf|        joined_words|          joined_idf|match|\n",
      "+------+-------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|100170|    kerosene heater|  1.0|Dyna-Glo Pro port...|  [kerosene, heater]|(10,[0,8],[1.1296...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|    0|\n",
      "|100170|     lp gas heaters| 2.67|Dyna-Glo Pro port...|  [lp, gas, heaters]|(10,[2,5,9],[1.26...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|    0|\n",
      "|100170|  portable air tank| 1.67|Dyna-Glo Pro port...|[portable, air, t...|(10,[3,4,7],[1.25...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|    0|\n",
      "|100170|thin propane heater| 2.33|Dyna-Glo Pro port...|[thin, propane, h...|(10,[0,2,7],[1.12...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|    0|\n",
      "|100274|       milwakee M12|  3.0|Milwaukee REDLITH...|     [milwakee, m12]|(10,[4,6],[1.2325...|[milwaukee, redli...|(10,[0,1,2,3,4,5,...|    0|\n",
      "+------+-------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "def jaccardSimilarity(term, joined):\n",
    "    jscore = 0\n",
    "    jscore =jaccard_similarity_score(term, joined)\n",
    "    print (jscore)\n",
    "    return jscore\n",
    "jaccardUDF=udf(jaccardSimilarity, DoubleType())\n",
    "\n",
    "#result = result.withColumn(\"term_joined_jaccard\", jaccardUDF(\"term_idf\", \"joined_idf\"))\n",
    "result.show(5)\n",
    "\n",
    "print (123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer,StringIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType,StringType,IntegerType\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import VectorAssembler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------+\n",
      "|   pid|                term|score|       joined_column|          term_words|            term_idf|        joined_words|          joined_idf|match|features|\n",
      "+------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------+\n",
      "|100170|     kerosene heater|  1.0|Dyna-Glo Pro port...|  [kerosene, heater]|(10,[0,8],[1.1296...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|    0|   [0.0]|\n",
      "|100170|      lp gas heaters| 2.67|Dyna-Glo Pro port...|  [lp, gas, heaters]|(10,[2,5,9],[1.26...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|    0|   [0.0]|\n",
      "|100170|   portable air tank| 1.67|Dyna-Glo Pro port...|[portable, air, t...|(10,[3,4,7],[1.25...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|    0|   [0.0]|\n",
      "|100170| thin propane heater| 2.33|Dyna-Glo Pro port...|[thin, propane, h...|(10,[0,2,7],[1.12...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|    0|   [0.0]|\n",
      "|100274|        milwakee M12|  3.0|Milwaukee REDLITH...|     [milwakee, m12]|(10,[4,6],[1.2325...|[milwaukee, redli...|(10,[0,1,2,3,4,5,...|    0|   [0.0]|\n",
      "|100274|       milwaukee m12| 1.67|Milwaukee REDLITH...|    [milwaukee, m12]|(10,[0,6],[1.1296...|[milwaukee, redli...|(10,[0,1,2,3,4,5,...|    2|   [2.0]|\n",
      "|100274|photoelectric/ion...| 1.67|Milwaukee REDLITH...|[photoelectric/io...|(10,[0,2,4],[1.12...|[milwaukee, redli...|(10,[0,1,2,3,4,5,...|    0|   [0.0]|\n",
      "|100446|  glaciar bay toiled| 2.67|Choose a half flu...|[glaciar, bay, to...|(10,[1,9],[2.7061...|[choose, a, half,...|(10,[0,1,2,3,4,5,...|    0|   [0.0]|\n",
      "|100446|glacier bay high ...| 1.67|Choose a half flu...|[glacier, bay, hi...|(10,[1,6,7,9],[1....|[choose, a, half,...|(10,[0,1,2,3,4,5,...|    0|   [0.0]|\n",
      "|100446|  toilet glacier bay|  3.0|Choose a half flu...|[toilet, glacier,...|(10,[1,9],[1.3530...|[choose, a, half,...|(10,[0,1,2,3,4,5,...|    0|   [0.0]|\n",
      "+------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "frame = result\n",
    "#features=[\"match\", \"term_joined_jaccard\"]\n",
    "features=[\"match\"]\n",
    "assembler_features = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "data = assembler_features.transform(frame)\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|features|\n",
      "+--------+\n",
      "|[0.0]   |\n",
      "|[0.0]   |\n",
      "|[0.0]   |\n",
      "|[0.0]   |\n",
      "|[0.0]   |\n",
      "|[2.0]   |\n",
      "|[0.0]   |\n",
      "|[0.0]   |\n",
      "|[0.0]   |\n",
      "|[0.0]   |\n",
      "|[0.0]   |\n",
      "|[0.0]   |\n",
      "|[0.0]   |\n",
      "|[0.0]   |\n",
      "|[0.0]   |\n",
      "|[0.0]   |\n",
      "|[0.0]   |\n",
      "|[0.0]   |\n",
      "|[0.0]   |\n",
      "|[0.0]   |\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(\"features\").show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------+\n",
      "|   pid|               term|score|       joined_column|          term_words|            term_idf|        joined_words|          joined_idf|match|features|\n",
      "+------+-------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------+\n",
      "|100170|    kerosene heater|  1.0|Dyna-Glo Pro port...|  [kerosene, heater]|(10,[0,8],[1.1296...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|    0|   [0.0]|\n",
      "|100170|     lp gas heaters| 2.67|Dyna-Glo Pro port...|  [lp, gas, heaters]|(10,[2,5,9],[1.26...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|    0|   [0.0]|\n",
      "|100170|  portable air tank| 1.67|Dyna-Glo Pro port...|[portable, air, t...|(10,[3,4,7],[1.25...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|    0|   [0.0]|\n",
      "|100170|thin propane heater| 2.33|Dyna-Glo Pro port...|[thin, propane, h...|(10,[0,2,7],[1.12...|[dyna-glo, pro, p...|(10,[0,1,2,3,4,5,...|    0|   [0.0]|\n",
      "|100274|       milwakee M12|  3.0|Milwaukee REDLITH...|     [milwakee, m12]|(10,[4,6],[1.2325...|[milwaukee, redli...|(10,[0,1,2,3,4,5,...|    0|   [0.0]|\n",
      "+------+-------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---+----+-----+-------------+----------+--------+------------+----------+-----+--------+\n",
      "|pid|term|score|joined_column|term_words|term_idf|joined_words|joined_idf|match|features|\n",
      "+---+----+-----+-------------+----------+--------+------------+----------+-----+--------+\n",
      "+---+----+-----+-------------+----------+--------+------------+----------+-----+--------+\n",
      "\n",
      "+------+--------+\n",
      "|pid   |features|\n",
      "+------+--------+\n",
      "|100170|[0.0]   |\n",
      "|100170|[0.0]   |\n",
      "|100170|[0.0]   |\n",
      "|100170|[0.0]   |\n",
      "|100274|[0.0]   |\n",
      "|100274|[2.0]   |\n",
      "|100274|[0.0]   |\n",
      "|100446|[0.0]   |\n",
      "|100446|[0.0]   |\n",
      "|100446|[0.0]   |\n",
      "+------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+---+--------+\n",
      "|pid|features|\n",
      "+---+--------+\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.registerTempTable(\"data\")\n",
    "trainData = sql_sc.sql(\"SELECT * from data where score is not NULL\")\n",
    "trainData.show(5)\n",
    "testData = sql_sc.sql(\"SELECT * from data where score is NULL\")\n",
    "testData.show(5)\n",
    "trainData.select(\"pid\", \"features\").show(10, truncate=False)\n",
    "testData.select(\"pid\", \"features\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(trainD, validD) = trainData.randomSplit([0.8,0.2])\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"score\", numTrees=11, maxDepth=5)\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "model=pipeline.fit(trainD)\n",
    "predictions = model.transform(validD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
