{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "# reference: Final 02\n",
    "test_data = pd.read_csv(\"/Users/yiwang/Documents/YiWang/Ebiz/Task 15/test-panda.csv\",encoding ='latin1')\n",
    "train_data = pd.read_csv('/Users/yiwang/Documents/YiWang/Ebiz/Task 15/train-panda.csv',encoding ='latin1')\n",
    "attributes = pd.read_csv(\"/Users/yiwang/Documents/YiWang/Ebiz/Task 15/attributes-panda.csv\",encoding ='latin1')\n",
    "product_description = pd.read_csv(\"/Users/yiwang/Documents/YiWang/Ebiz/Task 15/product_descriptions-panda.csv\",encoding ='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>BEHR Premium Textured DECKOVER is an innovativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>Classic architecture meets contemporary design...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>The Grape Solar 265-Watt Polycrystalline PV So...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>Update your bathroom with the Delta Vero Singl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_uid                                product_description\n",
       "0       100001  Not only do angles make joints stronger, they ...\n",
       "1       100002  BEHR Premium Textured DECKOVER is an innovativ...\n",
       "2       100003  Classic architecture meets contemporary design...\n",
       "3       100004  The Grape Solar 265-Watt Polycrystalline PV So...\n",
       "4       100005  Update your bathroom with the Delta Vero Singl..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()\n",
    "train_data.head()\n",
    "attributes.head()\n",
    "product_description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge attribute to find terms in query\n",
    "# reference: https://www.kaggle.com/junfeng/home-depot-product-search-relevance/sklearn-random-forest-merge-attributes\n",
    "def merge(attr):\n",
    "    #names = attr[\"name\"]\n",
    "    values = attr[\"value\"]\n",
    "    merge = []\n",
    "    for value in zip(values):\n",
    "        merge.append(\" \".join(value))\n",
    "    return \" \".join(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attributes.dropna(how=\"all\", inplace=True)\n",
    "attributes[\"product_uid\"] = attributes[\"product_uid\"].astype(int)\n",
    "attributes[\"value\"] = attributes[\"value\"].astype(str)\n",
    "product_attributes = attributes.groupby(\"product_uid\").apply(merge)\n",
    "product_attributes = product_attributes.reset_index(name=\"product_attributes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.merge(train_data, product_attributes, how=\"left\", on=\"product_uid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>relevance</th>\n",
       "      <th>product_attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Versatile connector for various 90Â° connectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Versatile connector for various 90Â° connectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>100002</td>\n",
       "      <td>BEHR Premium Textured DeckOver 1-gal. #SC-141 ...</td>\n",
       "      <td>deck over</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Brush,Roller,Spray 6.63 in 7.76 in 6.63 in Rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>100005</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>2.33</td>\n",
       "      <td>Combo Tub and Shower No Includes the trim kit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>100005</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "      <td>shower only faucet</td>\n",
       "      <td>2.67</td>\n",
       "      <td>Combo Tub and Shower No Includes the trim kit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>100006</td>\n",
       "      <td>Whirlpool 1.9 cu. ft. Over the Range Convectio...</td>\n",
       "      <td>convection otr</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Over the Range Microwave 18.5 in 17.13 in 29.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>100006</td>\n",
       "      <td>Whirlpool 1.9 cu. ft. Over the Range Convectio...</td>\n",
       "      <td>microwave over stove</td>\n",
       "      <td>2.67</td>\n",
       "      <td>Over the Range Microwave 18.5 in 17.13 in 29.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>100006</td>\n",
       "      <td>Whirlpool 1.9 cu. ft. Over the Range Convectio...</td>\n",
       "      <td>microwaves</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Over the Range Microwave 18.5 in 17.13 in 29.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>100007</td>\n",
       "      <td>Lithonia Lighting Quantum 2-Light Black LED Em...</td>\n",
       "      <td>emergency light</td>\n",
       "      <td>2.67</td>\n",
       "      <td>Ni-Cad .Built-In LED Advanced LED technology i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27</td>\n",
       "      <td>100009</td>\n",
       "      <td>House of Fara 3/4 in. x 3 in. x 8 ft. MDF Flut...</td>\n",
       "      <td>mdf 3/4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Door &amp; Window Made of primed MDF Can be painte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_uid                                      product_title  \\\n",
       "0   2       100001                  Simpson Strong-Tie 12-Gauge Angle   \n",
       "1   3       100001                  Simpson Strong-Tie 12-Gauge Angle   \n",
       "2   9       100002  BEHR Premium Textured DeckOver 1-gal. #SC-141 ...   \n",
       "3  16       100005  Delta Vero 1-Handle Shower Only Faucet Trim Ki...   \n",
       "4  17       100005  Delta Vero 1-Handle Shower Only Faucet Trim Ki...   \n",
       "5  18       100006  Whirlpool 1.9 cu. ft. Over the Range Convectio...   \n",
       "6  20       100006  Whirlpool 1.9 cu. ft. Over the Range Convectio...   \n",
       "7  21       100006  Whirlpool 1.9 cu. ft. Over the Range Convectio...   \n",
       "8  23       100007  Lithonia Lighting Quantum 2-Light Black LED Em...   \n",
       "9  27       100009  House of Fara 3/4 in. x 3 in. x 8 ft. MDF Flut...   \n",
       "\n",
       "            search_term  relevance  \\\n",
       "0         angle bracket       3.00   \n",
       "1             l bracket       2.50   \n",
       "2             deck over       3.00   \n",
       "3      rain shower head       2.33   \n",
       "4    shower only faucet       2.67   \n",
       "5        convection otr       3.00   \n",
       "6  microwave over stove       2.67   \n",
       "7            microwaves       3.00   \n",
       "8       emergency light       2.67   \n",
       "9               mdf 3/4       3.00   \n",
       "\n",
       "                                  product_attributes  \n",
       "0  Versatile connector for various 90Â° connectio...  \n",
       "1  Versatile connector for various 90Â° connectio...  \n",
       "2  Brush,Roller,Spray 6.63 in 7.76 in 6.63 in Rev...  \n",
       "3  Combo Tub and Shower No Includes the trim kit ...  \n",
       "4  Combo Tub and Shower No Includes the trim kit ...  \n",
       "5  Over the Range Microwave 18.5 in 17.13 in 29.9...  \n",
       "6  Over the Range Microwave 18.5 in 17.13 in 29.9...  \n",
       "7  Over the Range Microwave 18.5 in 17.13 in 29.9...  \n",
       "8  Ni-Cad .Built-In LED Advanced LED technology i...  \n",
       "9  Door & Window Made of primed MDF Can be painte...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data.drop(\"product_attributes_x\")\n",
    "#train_data.drop('product_description_x', axis=1, inplace=True)\n",
    "#train_data.drop('product_attributes_x', axis=1, inplace=True)\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_data = pd.merge(train_data, product_description, how=\"left\", on=\"product_uid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>relevance</th>\n",
       "      <th>product_attributes</th>\n",
       "      <th>product_description_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Versatile connector for various 90Â° connectio...</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Versatile connector for various 90Â° connectio...</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>100002</td>\n",
       "      <td>BEHR Premium Textured DeckOver 1-gal. #SC-141 ...</td>\n",
       "      <td>deck over</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Brush,Roller,Spray 6.63 in 7.76 in 6.63 in Rev...</td>\n",
       "      <td>BEHR Premium Textured DECKOVER is an innovativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>100005</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>2.33</td>\n",
       "      <td>Combo Tub and Shower No Includes the trim kit ...</td>\n",
       "      <td>Update your bathroom with the Delta Vero Singl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>100005</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "      <td>shower only faucet</td>\n",
       "      <td>2.67</td>\n",
       "      <td>Combo Tub and Shower No Includes the trim kit ...</td>\n",
       "      <td>Update your bathroom with the Delta Vero Singl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>100006</td>\n",
       "      <td>Whirlpool 1.9 cu. ft. Over the Range Convectio...</td>\n",
       "      <td>convection otr</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Over the Range Microwave 18.5 in 17.13 in 29.9...</td>\n",
       "      <td>Achieving delicious results is almost effortle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>100006</td>\n",
       "      <td>Whirlpool 1.9 cu. ft. Over the Range Convectio...</td>\n",
       "      <td>microwave over stove</td>\n",
       "      <td>2.67</td>\n",
       "      <td>Over the Range Microwave 18.5 in 17.13 in 29.9...</td>\n",
       "      <td>Achieving delicious results is almost effortle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>100006</td>\n",
       "      <td>Whirlpool 1.9 cu. ft. Over the Range Convectio...</td>\n",
       "      <td>microwaves</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Over the Range Microwave 18.5 in 17.13 in 29.9...</td>\n",
       "      <td>Achieving delicious results is almost effortle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>100007</td>\n",
       "      <td>Lithonia Lighting Quantum 2-Light Black LED Em...</td>\n",
       "      <td>emergency light</td>\n",
       "      <td>2.67</td>\n",
       "      <td>Ni-Cad .Built-In LED Advanced LED technology i...</td>\n",
       "      <td>The Quantum Adjustable 2-Light LED Black Emerg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27</td>\n",
       "      <td>100009</td>\n",
       "      <td>House of Fara 3/4 in. x 3 in. x 8 ft. MDF Flut...</td>\n",
       "      <td>mdf 3/4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Door &amp; Window Made of primed MDF Can be painte...</td>\n",
       "      <td>Get the House of Fara 3/4 in. x 3 in. x 8 ft. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_uid                                      product_title  \\\n",
       "0   2       100001                  Simpson Strong-Tie 12-Gauge Angle   \n",
       "1   3       100001                  Simpson Strong-Tie 12-Gauge Angle   \n",
       "2   9       100002  BEHR Premium Textured DeckOver 1-gal. #SC-141 ...   \n",
       "3  16       100005  Delta Vero 1-Handle Shower Only Faucet Trim Ki...   \n",
       "4  17       100005  Delta Vero 1-Handle Shower Only Faucet Trim Ki...   \n",
       "5  18       100006  Whirlpool 1.9 cu. ft. Over the Range Convectio...   \n",
       "6  20       100006  Whirlpool 1.9 cu. ft. Over the Range Convectio...   \n",
       "7  21       100006  Whirlpool 1.9 cu. ft. Over the Range Convectio...   \n",
       "8  23       100007  Lithonia Lighting Quantum 2-Light Black LED Em...   \n",
       "9  27       100009  House of Fara 3/4 in. x 3 in. x 8 ft. MDF Flut...   \n",
       "\n",
       "            search_term  relevance  \\\n",
       "0         angle bracket       3.00   \n",
       "1             l bracket       2.50   \n",
       "2             deck over       3.00   \n",
       "3      rain shower head       2.33   \n",
       "4    shower only faucet       2.67   \n",
       "5        convection otr       3.00   \n",
       "6  microwave over stove       2.67   \n",
       "7            microwaves       3.00   \n",
       "8       emergency light       2.67   \n",
       "9               mdf 3/4       3.00   \n",
       "\n",
       "                                  product_attributes  \\\n",
       "0  Versatile connector for various 90Â° connectio...   \n",
       "1  Versatile connector for various 90Â° connectio...   \n",
       "2  Brush,Roller,Spray 6.63 in 7.76 in 6.63 in Rev...   \n",
       "3  Combo Tub and Shower No Includes the trim kit ...   \n",
       "4  Combo Tub and Shower No Includes the trim kit ...   \n",
       "5  Over the Range Microwave 18.5 in 17.13 in 29.9...   \n",
       "6  Over the Range Microwave 18.5 in 17.13 in 29.9...   \n",
       "7  Over the Range Microwave 18.5 in 17.13 in 29.9...   \n",
       "8  Ni-Cad .Built-In LED Advanced LED technology i...   \n",
       "9  Door & Window Made of primed MDF Can be painte...   \n",
       "\n",
       "                               product_description_x  \n",
       "0  Not only do angles make joints stronger, they ...  \n",
       "1  Not only do angles make joints stronger, they ...  \n",
       "2  BEHR Premium Textured DECKOVER is an innovativ...  \n",
       "3  Update your bathroom with the Delta Vero Singl...  \n",
       "4  Update your bathroom with the Delta Vero Singl...  \n",
       "5  Achieving delicious results is almost effortle...  \n",
       "6  Achieving delicious results is almost effortle...  \n",
       "7  Achieving delicious results is almost effortle...  \n",
       "8  The Quantum Adjustable 2-Light LED Black Emerg...  \n",
       "9  Get the House of Fara 3/4 in. x 3 in. x 8 ft. ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data.drop('product_description_x', axis=1, inplace=True)\n",
    "train_data.drop('product_description_y', axis=1, inplace=True)\n",
    "train_data.head(10)\n",
    "#train_data.drop('product_attributes_y', axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------------------+------------------+-----+--------------------+--------------------+\n",
      "| id|   uid|               title|              term|score|          attributes|         description|\n",
      "+---+------+--------------------+------------------+-----+--------------------+--------------------+\n",
      "|  2|100001|Simpson Strong-Ti...|     angle bracket|  3.0|Versatile connect...|Not only do angle...|\n",
      "|  3|100001|Simpson Strong-Ti...|         l bracket|  2.5|Versatile connect...|Not only do angle...|\n",
      "|  9|100002|BEHR Premium Text...|         deck over|  3.0|Brush,Roller,Spra...|BEHR Premium Text...|\n",
      "| 16|100005|Delta Vero 1-Hand...|  rain shower head| 2.33|Combo Tub and Sho...|Update your bathr...|\n",
      "| 17|100005|Delta Vero 1-Hand...|shower only faucet| 2.67|Combo Tub and Sho...|Update your bathr...|\n",
      "+---+------+--------------------+------------------+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType,StringType,IntegerType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"test\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sql_sc = SQLContext(sc)\n",
    "\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sql_sc = SQLContext(sc)\n",
    "\n",
    "trainSchema = StructType([\n",
    "    StructField(\"id\", IntegerType()),\n",
    "    StructField(\"uid\", IntegerType()),\n",
    "    StructField(\"title\", StringType()),\n",
    "    StructField(\"term\", StringType()),\n",
    "    StructField(\"score\", DoubleType()),\n",
    "    StructField(\"attributes\", StringType()),\n",
    "    StructField(\"description\", StringType())\n",
    "])\n",
    "\n",
    "rawTrain = sql_sc.createDataFrame(train_data, trainSchema)\n",
    "rawTrain.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------------------+-------------+-----+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| id|   uid|               title|         term|score|          attributes|         description|         title_words|           title_idf|      term_words|            term_idf|          attr_words|       attr_filtered|   attr_filtered_idf|\n",
      "+---+------+--------------------+-------------+-----+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  2|100001|Simpson Strong-Ti...|angle bracket|  3.0|Versatile connect...|Not only do angle...|[simpson, strong-...|(10,[1,3],[0.5280...|[angle, bracket]|(10,[2,3],[1.2685...|[versatile, conne...|[versatile, conne...|(10,[0,1,2,3,4,5,...|\n",
      "|  3|100001|Simpson Strong-Ti...|    l bracket|  2.5|Versatile connect...|Not only do angle...|[simpson, strong-...|(10,[1,3],[0.5280...|    [l, bracket]|(10,[2,6],[1.2685...|[versatile, conne...|[versatile, conne...|(10,[0,1,2,3,4,5,...|\n",
      "|  9|100002|BEHR Premium Text...|    deck over|  3.0|Brush,Roller,Spra...|BEHR Premium Text...|[behr, premium, t...|(10,[0,1,3,4,5,7,...|    [deck, over]|(10,[2,9],[1.2685...|[brush,roller,spr...|[brush,roller,spr...|(10,[0,1,2,3,4,5,...|\n",
      "+---+------+--------------------+-------------+-----+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "DataFrame[id: int, uid: int, title: string, term: string, score: double, attributes: string, description: string, title_words: array<string>, title_idf: vector, term_words: array<string>, term_idf: vector, attr_words: array<string>, attr_filtered: array<string>, attr_filtered_idf: vector]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import NGram\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "#title\n",
    "    #tokenize\n",
    "tokenizer = Tokenizer(inputCol=\"title\", outputCol=\"title_words\")\n",
    "temp = tokenizer.transform(rawTrain)\n",
    "    #idf\n",
    "hashingTF = HashingTF(inputCol=\"title_words\", outputCol=\"rawFeatures\", numFeatures=10)\n",
    "temp = hashingTF.transform(temp)\n",
    "\n",
    "idf = IDF(inputCol = \"rawFeatures\", outputCol=\"title_idf\")\n",
    "idfModel = idf.fit(temp)\n",
    "temp = idfModel.transform(temp)\n",
    "temp=temp.drop(\"rawFeatures\")\n",
    "#     #n-gram , n = 2\n",
    "# ngram = NGram(n=2, inputCol=\"title\", outputCol=\"title_2grams\")\n",
    "# temp = ngram.transform(temp)\n",
    "#     #n-gram , n = 3\n",
    "# ngram = NGram(n=2, inputCol=\"title\", outputCol=\"title_3grams\")\n",
    "# temp = ngram.transform(temp)\n",
    "\n",
    "\n",
    "#temp=temp.drop('title')\n",
    "\n",
    "\n",
    "\n",
    "#tokenize terms\n",
    "tokenizer = Tokenizer(inputCol=\"term\", outputCol=\"term_words\")\n",
    "temp = tokenizer.transform(temp)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"term_words\", outputCol=\"rawFeatures\", numFeatures=10)\n",
    "temp = hashingTF.transform(temp)\n",
    "\n",
    "idf = IDF(inputCol = \"rawFeatures\", outputCol=\"term_idf\")\n",
    "idfModel = idf.fit(temp)\n",
    "temp = idfModel.transform(temp)\n",
    "temp=temp.drop(\"rawFeatures\")\n",
    "#temp=temp.drop('term')\n",
    "\n",
    "#tokenize attributes\n",
    "tokenizer = Tokenizer(inputCol=\"attributes\", outputCol=\"attr_words\")\n",
    "temp = tokenizer.transform(temp)\n",
    "\n",
    "remover1 = StopWordsRemover(inputCol=\"attr_words\", outputCol=\"attr_filtered\")\n",
    "temp = remover1.transform(temp)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"attr_filtered\", outputCol=\"rawFeatures\", numFeatures=10)\n",
    "temp = hashingTF.transform(temp)\n",
    "\n",
    "idf = IDF(inputCol = \"rawFeatures\", outputCol=\"attr_filtered_idf\")\n",
    "idfModel = idf.fit(temp)\n",
    "temp = idfModel.transform(temp)\n",
    "temp=temp.drop(\"rawFeatures\")\n",
    "#temp=temp.drop('attributes')\n",
    "\n",
    "\n",
    "temp.show(3)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------------------+-------------+-----+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| id|   uid|               title|         term|score|          attributes|         description|         title_words|           title_idf|      term_words|            term_idf|          attr_words|       attr_filtered|   attr_filtered_idf|         descr_words|      descr_filtered|  descr_filtered_idf|\n",
      "+---+------+--------------------+-------------+-----+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  2|100001|Simpson Strong-Ti...|angle bracket|  3.0|Versatile connect...|Not only do angle...|[simpson, strong-...|(10,[1,3],[0.5280...|[angle, bracket]|(10,[2,3],[1.2685...|[versatile, conne...|[versatile, conne...|(10,[0,1,2,3,4,5,...|[not, only, do, a...|[angles, make, jo...|(10,[0,1,2,3,4,5,...|\n",
      "|  3|100001|Simpson Strong-Ti...|    l bracket|  2.5|Versatile connect...|Not only do angle...|[simpson, strong-...|(10,[1,3],[0.5280...|    [l, bracket]|(10,[2,6],[1.2685...|[versatile, conne...|[versatile, conne...|(10,[0,1,2,3,4,5,...|[not, only, do, a...|[angles, make, jo...|(10,[0,1,2,3,4,5,...|\n",
      "|  9|100002|BEHR Premium Text...|    deck over|  3.0|Brush,Roller,Spra...|BEHR Premium Text...|[behr, premium, t...|(10,[0,1,3,4,5,7,...|    [deck, over]|(10,[2,9],[1.2685...|[brush,roller,spr...|[brush,roller,spr...|(10,[0,1,2,3,4,5,...|[behr, premium, t...|[behr, premium, t...|(10,[0,1,2,3,4,5,...|\n",
      "+---+------+--------------------+-------------+-----+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "DataFrame[id: int, uid: int, title: string, term: string, score: double, attributes: string, description: string, title_words: array<string>, title_idf: vector, term_words: array<string>, term_idf: vector, attr_words: array<string>, attr_filtered: array<string>, attr_filtered_idf: vector, descr_words: array<string>, descr_filtered: array<string>, descr_filtered_idf: vector]\n"
     ]
    }
   ],
   "source": [
    "#tokenize description\n",
    "tokenizer = Tokenizer(inputCol=\"description\", outputCol=\"descr_words\")\n",
    "temp = tokenizer.transform(temp)\n",
    "\n",
    "\n",
    "remover2 = StopWordsRemover(inputCol=\"descr_words\", outputCol=\"descr_filtered\")\n",
    "temp = remover2.transform(temp)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"descr_filtered\", outputCol=\"rawFeatures\", numFeatures=10)\n",
    "temp = hashingTF.transform(temp)\n",
    "\n",
    "idf = IDF(inputCol = \"rawFeatures\", outputCol=\"descr_filtered_idf\")\n",
    "idfModel = idf.fit(temp)\n",
    "temp = idfModel.transform(temp)\n",
    "temp=temp.drop(\"rawFeatures\")\n",
    "#temp=temp.drop(\"description\")\n",
    "\n",
    "\n",
    "#rawTrain.show(5)\n",
    "temp.show(3)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| id|   uid|score|         title_words|           title_idf|          term_words|            term_idf|          attr_words|            attr_idf|         descr_words|           descr_idf|       attr_filtered|      descr_filtered|          title_stem|\n",
      "+---+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  2|100001|  3.0|[simpson, strong-...|(10,[1,3],[0.5280...|    [angle, bracket]|(10,[2,3],[1.2685...|[versatile, conne...|(10,[0,1,2,3,4,5,...|[not, only, do, a...|(10,[0,1,2,3,4,5,...|[versatile, conne...|[angles, make, jo...|s   i   m   p   s...|\n",
      "|  3|100001|  2.5|[simpson, strong-...|(10,[1,3],[0.5280...|        [l, bracket]|(10,[2,6],[1.2685...|[versatile, conne...|(10,[0,1,2,3,4,5,...|[not, only, do, a...|(10,[0,1,2,3,4,5,...|[versatile, conne...|[angles, make, jo...|s   i   m   p   s...|\n",
      "|  9|100002|  3.0|[behr, premium, t...|(10,[0,1,3,4,5,7,...|        [deck, over]|(10,[2,9],[1.2685...|[brush,roller,spr...|(10,[0,1,2,3,4,5,...|[behr, premium, t...|(10,[0,1,2,3,4,5,...|[brush,roller,spr...|[behr, premium, t...|       b   e   h   r|\n",
      "| 16|100005| 2.33|[delta, vero, 1-h...|(10,[0,1,4,5,7,8,...|[rain, shower, head]|(10,[4,8],[2.4635...|[combo, tub, and,...|(10,[0,1,2,3,4,5,...|[update, your, ba...|(10,[0,1,2,3,4,5,...|[combo, tub, show...|[update, bathroom...|   d   e   l   t   a|\n",
      "| 17|100005| 2.67|[delta, vero, 1-h...|(10,[0,1,4,5,7,8,...|[shower, only, fa...|(10,[4,9],[1.2317...|[combo, tub, and,...|(10,[0,1,2,3,4,5,...|[update, your, ba...|(10,[0,1,2,3,4,5,...|[combo, tub, show...|[update, bathroom...|   d   e   l   t   a|\n",
      "+---+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType,StringType,IntegerType\n",
    "ps = PorterStemmer()\n",
    "\n",
    "#get stem words for term, and description&title&attributes\n",
    "def getStemWords(sentence):\n",
    "\n",
    "    merge = []\n",
    "    for s in sentence:\n",
    "        merge = \" \".join(ps.stem(s))\n",
    "        return \" \".join(merge)\n",
    "\n",
    "stemUDF = udf(getStemWords, StringType())\n",
    "test=temp.withColumn(\"title_stem\", stemUDF(\"title_words\"))\n",
    "test.drop('attributes').drop('description').show(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[id: int, uid: int, title: string, term: string, score: double, attributes: string, description: string, title_words: array<string>, title_idf: vector, term_words: array<string>, term_idf: vector, attr_words: array<string>, attr_filtered: array<string>, attr_filtered_idf: vector, descr_words: array<string>, descr_filtered: array<string>, descr_filtered_idf: vector]\n"
     ]
    }
   ],
   "source": [
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[id: int, uid: int, title: string, term: string, score: double, attributes: string, description: string, title_words: array<string>, title_idf: vector, term_words: array<string>, term_idf: vector, attr_words: array<string>, attr_filtered: array<string>, attr_filtered_idf: vector, descr_words: array<string>, descr_filtered: array<string>, descr_filtered_idf: vector, term_title_idfCS: double, term_attr_idfCS: double, term_descr_idfCS: double]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "import math\n",
    "def consineSimilarity(v1,v2):\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]\n",
    "        y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return float(sumxy/math.sqrt(sumxx*sumyy))\n",
    "idfUDF=udf(consineSimilarity,DoubleType())\n",
    "\n",
    "result = temp\n",
    "result = result.withColumn(\"term_title_idfCS\", idfUDF(\"term_idf\",\"title_idf\"))\n",
    "result = result.withColumn(\"term_attr_idfCS\", idfUDF(\"term_idf\",\"attr_filtered_idf\"))\n",
    "result = result.withColumn(\"term_descr_idfCS\", idfUDF(\"term_idf\",\"descr_filtered_idf\"))\n",
    "#result.show(5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------------------+-------------+-----+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+-------------------+------------------+----------------+---------------+----------------+\n",
      "| id|   uid|               title|         term|score|          attributes|         description|         title_words|           title_idf|      term_words|            term_idf|          attr_words|       attr_filtered|   attr_filtered_idf|         descr_words|      descr_filtered|  descr_filtered_idf|  term_title_idfCS|    term_attr_idfCS|  term_descr_idfCS|term_title_match|term_attr_match|term_descr_match|\n",
      "+---+------+--------------------+-------------+-----+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+-------------------+------------------+----------------+---------------+----------------+\n",
      "|  2|100001|Simpson Strong-Ti...|angle bracket|  3.0|Versatile connect...|Not only do angle...|[simpson, strong-...|(10,[1,3],[0.5280...|[angle, bracket]|(10,[2,3],[1.2685...|[versatile, conne...|[versatile, conne...|(10,[0,1,2,3,4,5,...|[not, only, do, a...|[angles, make, jo...|(10,[0,1,2,3,4,5,...|0.6497180409001693| 0.4825572980791222|0.3617569593147137|               2|              1|               3|\n",
      "|  3|100001|Simpson Strong-Ti...|    l bracket|  2.5|Versatile connect...|Not only do angle...|[simpson, strong-...|(10,[1,3],[0.5280...|    [l, bracket]|(10,[2,6],[1.2685...|[versatile, conne...|[versatile, conne...|(10,[0,1,2,3,4,5,...|[not, only, do, a...|[angles, make, jo...|(10,[0,1,2,3,4,5,...|               0.0|0.24405163592212437|0.3752210264145897|               1|             12|              16|\n",
      "|  9|100002|BEHR Premium Text...|    deck over|  3.0|Brush,Roller,Spra...|BEHR Premium Text...|[behr, premium, t...|(10,[0,1,3,4,5,7,...|    [deck, over]|(10,[2,9],[1.2685...|[brush,roller,spr...|[brush,roller,spr...|(10,[0,1,2,3,4,5,...|[behr, premium, t...|[behr, premium, t...|(10,[0,1,2,3,4,5,...|               0.0| 0.4124303071025185|0.3644175665256284|               2|              5|               8|\n",
      "+---+------+--------------------+-------------+-----+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+-------------------+------------------+----------------+---------------+----------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "DataFrame[id: int, uid: int, title: string, term: string, score: double, attributes: string, description: string, title_words: array<string>, title_idf: vector, term_words: array<string>, term_idf: vector, attr_words: array<string>, attr_filtered: array<string>, attr_filtered_idf: vector, descr_words: array<string>, descr_filtered: array<string>, descr_filtered_idf: vector, term_title_idfCS: double, term_attr_idfCS: double, term_descr_idfCS: double, term_title_match: int, term_attr_match: int, term_descr_match: int]\n"
     ]
    }
   ],
   "source": [
    "def matchWords(col,term):\n",
    "    l1 = len(col)\n",
    "    l2 = len(term)\n",
    "    match = 0\n",
    "    for i in range(l1):\n",
    "        for j in range(l2):\n",
    "            if col[i] == term[j]:\n",
    "                match+=2\n",
    "            elif col[i] in term[j]:\n",
    "                match+=1\n",
    "            elif term[j] in col[i]:\n",
    "                match+=1\n",
    "    return match\n",
    "matchUDF=udf(matchWords, IntegerType())\n",
    "\n",
    "result = result.withColumn(\"term_title_match\", matchUDF(\"title_words\",\"term_words\"))\n",
    "result = result.withColumn(\"term_attr_match\", matchUDF(\"attr_filtered\",\"term_words\"))\n",
    "result = result.withColumn(\"term_descr_match\", matchUDF(\"descr_filtered\",\"term_words\"))\n",
    "result.show(3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[id: int, uid: int, title: string, term: string, score: double, attributes: string, description: string, title_words: array<string>, title_idf: vector, term_words: array<string>, term_idf: vector, attr_words: array<string>, attr_filtered: array<string>, attr_filtered_idf: vector, descr_words: array<string>, descr_filtered: array<string>, descr_filtered_idf: vector, term_title_idfCS: double, term_attr_idfCS: double, term_descr_idfCS: double, term_title_match: int, term_attr_match: int, term_descr_match: int, term_title_dice: double, term_attr_dice: double, term_descr_dice: double]\n"
     ]
    }
   ],
   "source": [
    "def diceCoefficient(col, term):\n",
    "    setA = set(col)\n",
    "    setB = set(term)\n",
    "    overlap = len(setA & setB)\n",
    "    return float(overlap * 2.0 / (len(setA) + len(setB)))\n",
    "diceUDF = udf(diceCoefficient, DoubleType())\n",
    "\n",
    "result = result.withColumn(\"term_title_dice\", diceUDF(\"title_words\",\"term_words\"))\n",
    "result = result.withColumn(\"term_attr_dice\", diceUDF(\"attr_filtered\",\"term_words\"))\n",
    "result = result.withColumn(\"term_descr_dice\", diceUDF(\"descr_filtered\",\"term_words\"))\n",
    "#result.show(3)                                                      \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer,StringIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType,StringType,IntegerType\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "features = [\"term_title_match\", \"term_attr_match\",\"term_descr_match\",\"term_title_dice\",\"term_attr_dice\",\"term_descr_dice\",\"term_title_idfCS\", \"term_attr_idfCS\", \"term_descr_idfCS\"]\n",
    "\n",
    "assember_features = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "data = assember_features.transform(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                         |\n",
      "+-------------------------------------------------------------------------------------------------+\n",
      "|[2.0,1.0,3.0,0.3333333333333333,0.0,0.0,0.6497180409001693,0.4825572980791222,0.3617569593147137]|\n",
      "|[1.0,12.0,16.0,0.0,0.0,0.0,0.0,0.24405163592212437,0.3752210264145897]                           |\n",
      "|[2.0,5.0,8.0,0.0,0.0,0.0,0.0,0.4124303071025185,0.3644175665256284]                              |\n",
      "+-------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(\"features\").show(3,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------------------------------------------------------------------------------------------------+\n",
      "|id |uid   |features                                                                                         |\n",
      "+---+------+-------------------------------------------------------------------------------------------------+\n",
      "|2  |100001|[2.0,1.0,3.0,0.3333333333333333,0.0,0.0,0.6497180409001693,0.4825572980791222,0.3617569593147137]|\n",
      "|3  |100001|[1.0,12.0,16.0,0.0,0.0,0.0,0.0,0.24405163592212437,0.3752210264145897]                           |\n",
      "|9  |100002|[2.0,5.0,8.0,0.0,0.0,0.0,0.0,0.4124303071025185,0.3644175665256284]                              |\n",
      "+---+------+-------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+---+---+--------+\n",
      "|id |uid|features|\n",
      "+---+---+--------+\n",
      "+---+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.registerTempTable(\"data\")\n",
    "trainData = sql_sc.sql(\"SELECT * from data where score is not NULL\")\n",
    "testData = sql_sc.sql(\"SELECT * from data where score is NULL\")\n",
    "trainData.select(\"id\",\"uid\",\"features\").show(3,truncate=False)\n",
    "testData.select(\"id\",\"uid\",\"features\").show(3,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(trainD, validD) = trainData.randomSplit([0.8, 0.2])\n",
    "#featureIndexer =VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=5).fit(trainD)\n",
    "rf = RandomForestRegressor(featuresCol=\"features\",labelCol='score', numTrees=11,maxDepth=5)\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "model = pipeline.fit(trainD)\n",
    "predictions = model.transform(validD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.506939\n",
      "Mean Squared Error (MSE) on test data = 0.256987\n",
      "R^2 metric (R2) on test data = 0.0843933\n",
      "Mean Absolute Error (MAE) on test data = 0.415661\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"score\",predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions,{evaluator.metricName:\"rmse\"})\n",
    "mse = evaluator.evaluate(predictions,{evaluator.metricName:\"mse\"})\n",
    "r2 = evaluator.evaluate(predictions,{evaluator.metricName:\"r2\"})\n",
    "mae = evaluator.evaluate(predictions,{evaluator.metricName:\"mae\"})\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "print(\"Mean Squared Error (MSE) on test data = %g\" % mse)\n",
    "print(\"R^2 metric (R2) on test data = %g\" % r2)\n",
    "print(\"Mean Absolute Error (MAE) on test data = %g\" % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
